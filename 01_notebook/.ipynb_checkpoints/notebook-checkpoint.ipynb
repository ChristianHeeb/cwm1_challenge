{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge Wahrscheinlichkeitsmodellierung\n",
    "\n",
    "Autoren: Aaron Studer, Luca Gisler, Christian Heeb\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inhaltsverzeichnis:\n",
    "1. [Einführung](#introduction)\n",
    "2. [Aufgabenstellung](#task)\n",
    "3. [Grundlagen](#basics)\n",
    "4. [Setup](#setup)\n",
    "5. [Datenbereinigung](#datenbereinigung)\n",
    "    1. [Bereinigung Ablösezone 1](#datenbereinigung-1)\n",
    "    2. [Bereinigung Ablösezone 2](#datenbereinigung-2)\n",
    "    3. [Erweiterung Zeitdifferenz zwischen Datensatz](#datenerweiterung-1)\n",
    "    4. [Erweiterung Kinetische Energie](#datenerweiterung-2)\n",
    "    5. [Zusammenführung der Dateframes der Zone 1 & 2](#datentransformation-1)\n",
    "6. [Analyse der Daten](#dataanalysis)\n",
    "    1. [Boxplots](#dataanalysis-1)\n",
    "    2. [Histogramme](#dataanalysis-2)\n",
    "    3. [Streudiagramme](#dataanalysis-3)\n",
    "    4. [Zeitliche Verteilung der Steinschläge](#dataanalysis-4)\n",
    "        1. [Stündliche Verkehrsdichte](#dataanalysis-4-1)\n",
    "    5. [Beurteilung Ablösezone 1 ](#dataexamination-1)\n",
    "        1. [Geschwindigkeit](#dataexamination-1-1)\n",
    "        2. [Masse](#dataexamination-1-2)\n",
    "        3. [Zeitdifferenz](#dataexamination-1-3)\n",
    "    6. [Beurteilung Ablösezone 1 ](#dataexamination-2)\n",
    "        1. [Geschwindigkeit](#dataexamination-2-1)\n",
    "        2. [Masse](#dataexamination-2-2)\n",
    "        3. [Zeitdifferenz](#dataexamination-2-3)\n",
    "    7. [Übersicht der ausgewählten Verteilungen in Zone 1 und 2](#dataexamination-1-and-2)\n",
    "7. [Simulation der Daten](#datasimulation)\n",
    "    1. [Simulation der Zone 1](#datasimulation-1)\n",
    "    2. [Simulation der Zone 2](#datasimulation-2)\n",
    "8. [Bedingung für das Zerreissen des Sicherheitsnetzes](#requirements)\n",
    "    1. [Auto wird von Stein getroffen](#use-case-1)\n",
    "9. [Fazit](#simulation-result)\n",
    "10. [Quellen](#sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einführung <a name=\"introduction\"></a>\n",
    "\n",
    "Dieses Notebook enthaltet unsere Abgabe für die Challenge CWM1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabenstellung <a name=\"task\"></a>\n",
    "\n",
    "Die Kantonsstrasse unterhalb Schiers (GR) ist vom Steinschlag betroffen. Steine lösen sich von zwei unterschiedlichen Stellen an der Felswand ab (Ablösungszone 1 und Ablösungszone 2). Der betroffene Strassenabschnitt ist mit Steinfangnetzen gesichert, die jedoch in die Jahre gekommen sind und die angestrebte Sicherheit nicht mehr gewährleisten können. Die Planung für Ersatznetze hat bereits begonnen, kann aber frühstens in einem Jahr umgesetzt werden.\n",
    "\n",
    "In den letzten Monaten haben sich mehrere Steinschlagereignisse ereignet. Kommt es im Lauf des nächsten Jahres zu weiteren vergleichbaren Ereignissen, könnten die alten Sicherheitsnetze versagen und die Verkehrsteilnehmer einem grossen Sicherheitsrisiko ausgesetzt sein. Die Bevölkerung ist verunsichert und der Kantonsingenieur muss schnell entscheiden, ob das Risiko für die Verkehrsteilnehmer zu gross ist und die Kantonsstrasse vorübergehend gesperrt werden muss. Der Kantonsingenieur hat sie beauftragt, anhand der vorhanden Daten die Wahrscheinlichkeit eines Todesfalls zu berechnen und eine Empfehlung bezüglich der Schliessung bzw Offenhaltung der Strasse auszusprechen.\n",
    "\n",
    "Damit die Strasse offen bleiben kann, muss gezeigt werden, dass die jährliche Wahrscheinlichkeit von Todesfällen infolge Steinschlags kleiner als 0.0001 ist. Für die Berechnungen soll ein gut strukturierter und dokumentierter Code in Python oder R entwickelt werden.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grundlagen <a name=\"basics\"></a>\n",
    "\n",
    "Für die Planung der neuen Sicherheitsnetze, hat ein beauftragter Geologe, über drei Monate Daten zu den Steinschlagereignissen aufgenommen. Dabei wurde Steingeschwindigkeit, Steinmasse und Zeitpunkt und der Zeitpunkt das Ereignis registriert. Diese Daten können von Ihnen zur Modellbildung verwendet werden und stehen unter folgenden Links zur Verfügung:\n",
    "\n",
    "Ereignis aus Ablösungszone 1: https://www.dropbox.com/s/i58gdv6pzi03rhr/out_1.csv?dl=0\n",
    "\n",
    "Ereignis aus Ablösungszone 2: https://www.dropbox.com/s/3nk9pv7nzz8f0qb/out_2.csv?dl=0\n",
    "\n",
    "NB: Die Geschwindigkeit ist durch einen Radar aufgenommen und sehr präzise. Die Masse ist eine Experten-Schätzung des Geologen.\n",
    "\n",
    "Ein beauftragtes Ingenieurbüro hat geschätzt, dass die Sicherheitsnetze bis zu einer Aufprallenergie von 1000 kJ sicher sind. Falls bereits ein Stein mit über 2000 kg in den Sicherheitsnetzen liegt, beträgt die Aufprallenergie, die von den Sicherheitsnetzen aufgenommen werden kann, nur noch 500 kJ. Steine in den Sicherheitsnetzen werden vom Unterhaltsteam entfernt (die Reaktionszeit beträgt 24 Stunden).\n",
    "\n",
    "Das tägliche Verkehrsaufkommen beträgt 1200 Autos. Stau kommt auf der Strecke nicht vor. Die Tempolimite beträgt 60 km/h\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup <a name=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:09.626183Z",
     "start_time": "2023-06-12T10:37:09.303569Z"
    }
   },
   "outputs": [],
   "source": [
    "#prepration of workspace\n",
    "import pandas as pd\n",
    "import matplotlib.dates as mdates\n",
    "from fitter import Fitter, get_common_distributions\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:12.330320Z",
     "start_time": "2023-06-12T10:37:09.305370Z"
    }
   },
   "outputs": [],
   "source": [
    "#import df\n",
    "df_zone1 = pd.read_csv(\"https://www.dropbox.com/s/i58gdv6pzi03rhr/out_1.csv?dl=1\")\n",
    "df_zone2 = pd.read_csv(\"https://www.dropbox.com/s/3nk9pv7nzz8f0qb/out_2.csv?dl=1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datenbereinigung <a name=\"datenbereinigung\"></a>\n",
    "## Daten zu Ablösezone 1 bereinigen <a name=\"datenbereinigung-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:12.347538Z",
     "start_time": "2023-06-12T10:37:12.336247Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datum</th>\n",
       "      <th>Uhrzeit</th>\n",
       "      <th>Masse [kg]</th>\n",
       "      <th>Geschwindigkeit [m/s]</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 67</th>\n",
       "      <th>Unnamed: 68</th>\n",
       "      <th>Unnamed: 69</th>\n",
       "      <th>Unnamed: 70</th>\n",
       "      <th>Unnamed: 71</th>\n",
       "      <th>Unnamed: 72</th>\n",
       "      <th>Unnamed: 73</th>\n",
       "      <th>Unnamed: 74</th>\n",
       "      <th>Unnamed: 75</th>\n",
       "      <th>Unnamed: 76</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>09:00</td>\n",
       "      <td>194.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>21:00</td>\n",
       "      <td>224.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>14:00</td>\n",
       "      <td>3104.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>15:00</td>\n",
       "      <td>228.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>23:00</td>\n",
       "      <td>755.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Datum Uhrzeit  Masse [kg]  Geschwindigkeit [m/s]  Unnamed: 4  \\\n",
       "0  2019-01-01   09:00       194.0                    8.4         NaN   \n",
       "1  2019-01-01   21:00       224.0                    8.8         NaN   \n",
       "2  2019-01-02   14:00      3104.0                    9.2         NaN   \n",
       "3  2019-01-04   15:00       228.0                    8.0         NaN   \n",
       "4  2019-01-05   23:00       755.0                    7.0         NaN   \n",
       "\n",
       "   Unnamed: 5  Unnamed: 6  Unnamed: 7  Unnamed: 8  Unnamed: 9  ...  \\\n",
       "0         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "1         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "2         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "3         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "4         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "\n",
       "   Unnamed: 67  Unnamed: 68  Unnamed: 69  Unnamed: 70  Unnamed: 71  \\\n",
       "0          NaN          NaN          NaN          NaN          NaN   \n",
       "1          NaN          NaN          NaN          NaN          NaN   \n",
       "2          NaN          NaN          NaN          NaN          NaN   \n",
       "3          NaN          NaN          NaN          NaN          NaN   \n",
       "4          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "   Unnamed: 72  Unnamed: 73  Unnamed: 74  Unnamed: 75  Unnamed: 76  \n",
       "0          NaN          NaN          NaN          NaN          NaN  \n",
       "1          NaN          NaN          NaN          NaN          NaN  \n",
       "2          NaN          NaN          NaN          NaN          NaN  \n",
       "3          NaN          NaN          NaN          NaN          NaN  \n",
       "4          NaN          NaN          NaN          NaN          NaN  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#explore dataset\n",
    "df_zone1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:12.350021Z",
     "start_time": "2023-06-12T10:37:12.347761Z"
    }
   },
   "outputs": [],
   "source": [
    "#rename columns\n",
    "df_zone1 = df_zone1.rename(columns={\"Datum\": \"date\", \"Uhrzeit\": \"time\", \"Masse [kg]\": \"mass [kg]\", \"Geschwindigkeit [m/s]\": \"vel [m/s]\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:12.379182Z",
     "start_time": "2023-06-12T10:37:12.356263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>mass [kg]</th>\n",
       "      <th>vel [m/s]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>09:00</td>\n",
       "      <td>194.0</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>21:00</td>\n",
       "      <td>224.0</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>14:00</td>\n",
       "      <td>3104.0</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>15:00</td>\n",
       "      <td>228.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>23:00</td>\n",
       "      <td>755.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>16:00</td>\n",
       "      <td>167.0</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2019-03-22</td>\n",
       "      <td>18:00</td>\n",
       "      <td>2847.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2019-03-26</td>\n",
       "      <td>00:00</td>\n",
       "      <td>44.0</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2019-03-26</td>\n",
       "      <td>06:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2019-03-27</td>\n",
       "      <td>16:00</td>\n",
       "      <td>312.0</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date   time  mass [kg]  vel [m/s]\n",
       "0   2019-01-01  09:00      194.0        8.4\n",
       "1   2019-01-01  21:00      224.0        8.8\n",
       "2   2019-01-02  14:00     3104.0        9.2\n",
       "3   2019-01-04  15:00      228.0        8.0\n",
       "4   2019-01-05  23:00      755.0        7.0\n",
       "..         ...    ...        ...        ...\n",
       "63  2019-03-18  16:00      167.0        8.9\n",
       "64  2019-03-22  18:00     2847.0        7.0\n",
       "65  2019-03-26  00:00       44.0        8.9\n",
       "66  2019-03-26  06:00       45.0        8.4\n",
       "67  2019-03-27  16:00      312.0        5.8\n",
       "\n",
       "[68 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#remove NaN values\n",
    "df_zone1 = pd.DataFrame(df_zone1)\n",
    "df_zone1.drop(df_zone1.iloc[:, 4:77],axis = 1, inplace = True )\n",
    "df_zone1 = df_zone1.iloc[0:68]\n",
    "display(df_zone1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:12.379285Z",
     "start_time": "2023-06-12T10:37:12.359938Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date          object\n",
       "time          object\n",
       "mass [kg]    float64\n",
       "vel [m/s]    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check datatypes\n",
    "df_zone1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:12.394248Z",
     "start_time": "2023-06-12T10:37:12.364242Z"
    }
   },
   "outputs": [],
   "source": [
    "#change datatype of column \"date\" from object to DateTime\n",
    "\n",
    "#connect column date and time but also keep time row for later use\n",
    "df_zone1[\"time [h]\"] = df_zone1[\"time\"]\n",
    "\n",
    "df_zone1[\"date\"] = pd.to_datetime(df_zone1[\"date\"] + \" \" + df_zone1[\"time\"])\n",
    "\n",
    "#rearrange columns\n",
    "df_zone1 = df_zone1[[\"date\", \"time [h]\", \"mass [kg]\", \"vel [m/s]\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:12.407099Z",
     "start_time": "2023-06-12T10:37:12.367312Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date         datetime64[ns]\n",
       "time [h]             object\n",
       "mass [kg]           float64\n",
       "vel [m/s]           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check datatypes\n",
    "df_zone1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:12.407157Z",
     "start_time": "2023-06-12T10:37:12.370085Z"
    }
   },
   "outputs": [],
   "source": [
    "#sort df by date\n",
    "df_zone1.sort_values(by = \"date\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:12.407212Z",
     "start_time": "2023-06-12T10:37:12.375767Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time [h]</th>\n",
       "      <th>mass [kg]</th>\n",
       "      <th>vel [m/s]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 09:00:00</td>\n",
       "      <td>09:00</td>\n",
       "      <td>194.0</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 21:00:00</td>\n",
       "      <td>21:00</td>\n",
       "      <td>224.0</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-02 14:00:00</td>\n",
       "      <td>14:00</td>\n",
       "      <td>3104.0</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-04 15:00:00</td>\n",
       "      <td>15:00</td>\n",
       "      <td>228.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-05 23:00:00</td>\n",
       "      <td>23:00</td>\n",
       "      <td>755.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2019-03-18 16:00:00</td>\n",
       "      <td>16:00</td>\n",
       "      <td>167.0</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2019-03-22 18:00:00</td>\n",
       "      <td>18:00</td>\n",
       "      <td>2847.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2019-03-26 00:00:00</td>\n",
       "      <td>00:00</td>\n",
       "      <td>44.0</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2019-03-26 06:00:00</td>\n",
       "      <td>06:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2019-03-27 16:00:00</td>\n",
       "      <td>16:00</td>\n",
       "      <td>312.0</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date time [h]  mass [kg]  vel [m/s]\n",
       "0  2019-01-01 09:00:00    09:00      194.0        8.4\n",
       "1  2019-01-01 21:00:00    21:00      224.0        8.8\n",
       "2  2019-01-02 14:00:00    14:00     3104.0        9.2\n",
       "3  2019-01-04 15:00:00    15:00      228.0        8.0\n",
       "4  2019-01-05 23:00:00    23:00      755.0        7.0\n",
       "..                 ...      ...        ...        ...\n",
       "63 2019-03-18 16:00:00    16:00      167.0        8.9\n",
       "64 2019-03-22 18:00:00    18:00     2847.0        7.0\n",
       "65 2019-03-26 00:00:00    00:00       44.0        8.9\n",
       "66 2019-03-26 06:00:00    06:00       45.0        8.4\n",
       "67 2019-03-27 16:00:00    16:00      312.0        5.8\n",
       "\n",
       "[68 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_zone1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten zu Ablösezone 2 bereinigen <a name=\"datenbereinigung-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:12.421409Z",
     "start_time": "2023-06-12T10:37:12.385081Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Uhrzeit</th>\n",
       "      <th>m [kg]</th>\n",
       "      <th>v [m/s]</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "      <th>Unnamed: 24</th>\n",
       "      <th>Unnamed: 25</th>\n",
       "      <th>Unnamed: 26</th>\n",
       "      <th>Unnamed: 27</th>\n",
       "      <th>Unnamed: 28</th>\n",
       "      <th>Unnamed: 29</th>\n",
       "      <th>Unnamed: 30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>09:00</td>\n",
       "      <td>38.0</td>\n",
       "      <td>45.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>06:00</td>\n",
       "      <td>187.0</td>\n",
       "      <td>41.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>10:00</td>\n",
       "      <td>36.0</td>\n",
       "      <td>44.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>14:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>41.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-11</td>\n",
       "      <td>06:00</td>\n",
       "      <td>65.0</td>\n",
       "      <td>39.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Uhrzeit  m [kg]  v [m/s]  Unnamed: 4  Unnamed: 5  Unnamed: 6  \\\n",
       "0  2019-01-01   09:00    38.0     45.4         NaN         NaN         NaN   \n",
       "1  2019-01-03   06:00   187.0     41.6         NaN         NaN         NaN   \n",
       "2  2019-01-04   10:00    36.0     44.6         NaN         NaN         NaN   \n",
       "3  2019-01-07   14:00     6.0     41.2         NaN         NaN         NaN   \n",
       "4  2019-01-11   06:00    65.0     39.6         NaN         NaN         NaN   \n",
       "\n",
       "   Unnamed: 7  Unnamed: 8  Unnamed: 9  ...  Unnamed: 21  Unnamed: 22  \\\n",
       "0         NaN         NaN         NaN  ...          NaN          NaN   \n",
       "1         NaN         NaN         NaN  ...          NaN          NaN   \n",
       "2         NaN         NaN         NaN  ...          NaN          NaN   \n",
       "3         NaN         NaN         NaN  ...          NaN          NaN   \n",
       "4         NaN         NaN         NaN  ...          NaN          NaN   \n",
       "\n",
       "   Unnamed: 23  Unnamed: 24  Unnamed: 25  Unnamed: 26  Unnamed: 27  \\\n",
       "0          NaN          NaN          NaN          NaN          NaN   \n",
       "1          NaN          NaN          NaN          NaN          NaN   \n",
       "2          NaN          NaN          NaN          NaN          NaN   \n",
       "3          NaN          NaN          NaN          NaN          NaN   \n",
       "4          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "   Unnamed: 28  Unnamed: 29  Unnamed: 30  \n",
       "0          NaN          NaN          NaN  \n",
       "1          NaN          NaN          NaN  \n",
       "2          NaN          NaN          NaN  \n",
       "3          NaN          NaN          NaN  \n",
       "4          NaN          NaN          NaN  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#explore dataset\n",
    "df_zone2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:12.421475Z",
     "start_time": "2023-06-12T10:37:12.387618Z"
    }
   },
   "outputs": [],
   "source": [
    "#rename columns\n",
    "df_zone2 = df_zone2.rename(columns={\"Date\": \"date\", \"Uhrzeit\": \"time\", \"m [kg]\": \"mass [kg]\", \"v [m/s]\": \"vel [m/s]\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:12.421527Z",
     "start_time": "2023-06-12T10:37:12.394288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>mass [kg]</th>\n",
       "      <th>vel [m/s]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>09:00</td>\n",
       "      <td>38.0</td>\n",
       "      <td>45.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>06:00</td>\n",
       "      <td>187.0</td>\n",
       "      <td>41.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>10:00</td>\n",
       "      <td>36.0</td>\n",
       "      <td>44.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>14:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>41.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-11</td>\n",
       "      <td>06:00</td>\n",
       "      <td>65.0</td>\n",
       "      <td>39.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   time  mass [kg]  vel [m/s]\n",
       "0  2019-01-01  09:00       38.0       45.4\n",
       "1  2019-01-03  06:00      187.0       41.6\n",
       "2  2019-01-04  10:00       36.0       44.6\n",
       "3  2019-01-07  14:00        6.0       41.2\n",
       "4  2019-01-11  06:00       65.0       39.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#remove NaN values\n",
    "df_zone2 = pd.DataFrame(df_zone2)\n",
    "df_zone2.drop(df_zone2.iloc[:, 4:77],axis = 1, inplace = True )\n",
    "df_zone2 = df_zone2.iloc[0:32]\n",
    "display(df_zone2.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:12.421579Z",
     "start_time": "2023-06-12T10:37:12.394505Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date          object\n",
       "time          object\n",
       "mass [kg]    float64\n",
       "vel [m/s]    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check datatypes\n",
    "df_zone2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:12.454436Z",
     "start_time": "2023-06-12T10:37:12.397891Z"
    }
   },
   "outputs": [],
   "source": [
    "#change datatype of column \"date\" from object to DateTime\n",
    "\n",
    "#connect column date and time but also keep time row for later use\n",
    "df_zone2[\"time [h]\"] = df_zone2[\"time\"]\n",
    "df_zone2[\"date\"] = pd.to_datetime(df_zone2[\"date\"] + \" \" + df_zone2[\"time\"])\n",
    "\n",
    "#rearrange columns\n",
    "df_zone2 = df_zone2[[\"date\", \"time [h]\", \"mass [kg]\", \"vel [m/s]\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:12.454660Z",
     "start_time": "2023-06-12T10:37:12.401012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date         datetime64[ns]\n",
       "time [h]             object\n",
       "mass [kg]           float64\n",
       "vel [m/s]           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check datatypes\n",
    "df_zone2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:12.454697Z",
     "start_time": "2023-06-12T10:37:12.404Z"
    }
   },
   "outputs": [],
   "source": [
    "#sort df by date\n",
    "df_zone2.sort_values(by = \"date\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:12.454785Z",
     "start_time": "2023-06-12T10:37:12.415139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time [h]</th>\n",
       "      <th>mass [kg]</th>\n",
       "      <th>vel [m/s]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 09:00:00</td>\n",
       "      <td>09:00</td>\n",
       "      <td>38.0</td>\n",
       "      <td>45.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-03 06:00:00</td>\n",
       "      <td>06:00</td>\n",
       "      <td>187.0</td>\n",
       "      <td>41.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-04 10:00:00</td>\n",
       "      <td>10:00</td>\n",
       "      <td>36.0</td>\n",
       "      <td>44.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-07 14:00:00</td>\n",
       "      <td>14:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>41.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-11 06:00:00</td>\n",
       "      <td>06:00</td>\n",
       "      <td>65.0</td>\n",
       "      <td>39.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date time [h]  mass [kg]  vel [m/s]\n",
       "0 2019-01-01 09:00:00    09:00       38.0       45.4\n",
       "1 2019-01-03 06:00:00    06:00      187.0       41.6\n",
       "2 2019-01-04 10:00:00    10:00       36.0       44.6\n",
       "3 2019-01-07 14:00:00    14:00        6.0       41.2\n",
       "4 2019-01-11 06:00:00    06:00       65.0       39.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_zone2.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bereinigen der Messfehler <a name=\"datenbereinigung-3\"></a>\n",
    "In der bezeichneten Zone Zwei wurde bei der Datenerfassung vom 10. März 2019 eine Masse von 0.0 Kg dokumentiert. Da diese Eintragung unmöglich ist, impliziert sie einen Fehler innerhalb des Datensatzes.\n",
    "Zur Korrektur dieses Fehlers stehen verschiedene Optionen zur Verfügung, einschliesslich der Löschung des fehlerhaften Eintrags oder der Ersetzung durch einen geeigneten Ersatzwert, wie beispielsweise den Median aller vorhandenen Messwerte.\n",
    "In Anbetracht der Grösse unseres Datensatzes, der als relativ klein klassifiziert wird, erscheint eine Imputation als geeignete Lösung. Durch diesen Prozess werden fehlende oder fehlerhafte Daten durch plausible Werte ersetzt, wodurch die Stichprobengrösse beibehalten und Verzerrungen minimiert werden können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:12.454829Z",
     "start_time": "2023-06-12T10:37:12.415342Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time [h]</th>\n",
       "      <th>mass [kg]</th>\n",
       "      <th>vel [m/s]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 09:00:00</td>\n",
       "      <td>09:00</td>\n",
       "      <td>38.0</td>\n",
       "      <td>45.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-03 06:00:00</td>\n",
       "      <td>06:00</td>\n",
       "      <td>187.0</td>\n",
       "      <td>41.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-04 10:00:00</td>\n",
       "      <td>10:00</td>\n",
       "      <td>36.0</td>\n",
       "      <td>44.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-07 14:00:00</td>\n",
       "      <td>14:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>41.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-11 06:00:00</td>\n",
       "      <td>06:00</td>\n",
       "      <td>65.0</td>\n",
       "      <td>39.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date time [h]  mass [kg]  vel [m/s]\n",
       "0 2019-01-01 09:00:00    09:00       38.0       45.4\n",
       "1 2019-01-03 06:00:00    06:00      187.0       41.6\n",
       "2 2019-01-04 10:00:00    10:00       36.0       44.6\n",
       "3 2019-01-07 14:00:00    14:00        6.0       41.2\n",
       "4 2019-01-11 06:00:00    06:00       65.0       39.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#determine median df_zone 2\n",
    "median_zone2 = df_zone2[\"mass [kg]\"].median()\n",
    "\n",
    "#input value to df\n",
    "df_zone2.loc[df_zone2[\"mass [kg]\"] <= 0, \"mass [kg]\"] = median_zone2\n",
    "\n",
    "#show data\n",
    "display(df_zone2.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:12.454893Z",
     "start_time": "2023-06-12T10:37:12.417156Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time [h]</th>\n",
       "      <th>mass [kg]</th>\n",
       "      <th>vel [m/s]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 09:00:00</td>\n",
       "      <td>09:00</td>\n",
       "      <td>194.0</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 21:00:00</td>\n",
       "      <td>21:00</td>\n",
       "      <td>224.0</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-02 14:00:00</td>\n",
       "      <td>14:00</td>\n",
       "      <td>3104.0</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-04 15:00:00</td>\n",
       "      <td>15:00</td>\n",
       "      <td>228.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-05 23:00:00</td>\n",
       "      <td>23:00</td>\n",
       "      <td>755.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date time [h]  mass [kg]  vel [m/s]\n",
       "0 2019-01-01 09:00:00    09:00      194.0        8.4\n",
       "1 2019-01-01 21:00:00    21:00      224.0        8.8\n",
       "2 2019-01-02 14:00:00    14:00     3104.0        9.2\n",
       "3 2019-01-04 15:00:00    15:00      228.0        8.0\n",
       "4 2019-01-05 23:00:00    23:00      755.0        7.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time [h]</th>\n",
       "      <th>mass [kg]</th>\n",
       "      <th>vel [m/s]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 09:00:00</td>\n",
       "      <td>09:00</td>\n",
       "      <td>38.0</td>\n",
       "      <td>45.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-03 06:00:00</td>\n",
       "      <td>06:00</td>\n",
       "      <td>187.0</td>\n",
       "      <td>41.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-04 10:00:00</td>\n",
       "      <td>10:00</td>\n",
       "      <td>36.0</td>\n",
       "      <td>44.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-07 14:00:00</td>\n",
       "      <td>14:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>41.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-11 06:00:00</td>\n",
       "      <td>06:00</td>\n",
       "      <td>65.0</td>\n",
       "      <td>39.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date time [h]  mass [kg]  vel [m/s]\n",
       "0 2019-01-01 09:00:00    09:00       38.0       45.4\n",
       "1 2019-01-03 06:00:00    06:00      187.0       41.6\n",
       "2 2019-01-04 10:00:00    10:00       36.0       44.6\n",
       "3 2019-01-07 14:00:00    14:00        6.0       41.2\n",
       "4 2019-01-11 06:00:00    06:00       65.0       39.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#sort data by Date\n",
    "df_zone1.sort_values(by = \"date\", ascending = True, inplace = True)\n",
    "display(df_zone1.head(5))\n",
    "\n",
    "df_zone2.sort_values(by = \"date\", ascending = True, inplace = True)\n",
    "display(df_zone2.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zeitdifferenz zwischen Ablösungen berechnen <a name=\"datenerweiterung-1\"></a>\n",
    "\n",
    "Eine wichtige Information welche zur Analyse und Simulation der Daten benötigt wird, ist die Zeitdifferenz zwischen den einzelnen Steinschlägen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:12.468728Z",
     "start_time": "2023-06-12T10:37:12.425187Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot convert from timedelta64[ns] to timedelta64[h]. Supported resolutions are 's', 'ms', 'us', 'ns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#create column to assign running time difference in hours\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#Zone 1\u001b[39;00m\n\u001b[0;32m      3\u001b[0m df_zone1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimediff [h]\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 4\u001b[0m df_zone1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimediff [h]\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mdf_zone1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdf_zone1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshift\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtimedelta64[h]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# replace first NaN with 0\u001b[39;00m\n\u001b[0;32m      7\u001b[0m df_zone1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimediff [h]\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m,inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Bachelor\\Challenges\\cwm1\\cwm1_challenge\\venv\\Lib\\site-packages\\pandas\\core\\generic.py:6324\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6317\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6318\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[:, i]\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m   6319\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[0;32m   6320\u001b[0m     ]\n\u001b[0;32m   6322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6323\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6324\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6327\u001b[0m \u001b[38;5;66;03m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[1;32m~\\Bachelor\\Challenges\\cwm1\\cwm1_challenge\\venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:451\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    449\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Bachelor\\Challenges\\cwm1\\cwm1_challenge\\venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    355\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\Bachelor\\Challenges\\cwm1\\cwm1_challenge\\venv\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:511\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    493\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    509\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m--> 511\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    513\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    515\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Bachelor\\Challenges\\cwm1\\cwm1_challenge\\venv\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:242\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    239\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 242\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\Bachelor\\Challenges\\cwm1\\cwm1_challenge\\venv\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:184\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# i.e. ExtensionArray\u001b[39;00m\n\u001b[1;32m--> 184\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\Bachelor\\Challenges\\cwm1\\cwm1_challenge\\venv\\Lib\\site-packages\\pandas\\core\\arrays\\timedeltas.py:363\u001b[0m, in \u001b[0;36mTimedeltaArray.astype\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_simple_new(\n\u001b[0;32m    360\u001b[0m             res_values, dtype\u001b[38;5;241m=\u001b[39mres_values\u001b[38;5;241m.\u001b[39mdtype, freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfreq\n\u001b[0;32m    361\u001b[0m         )\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    364\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupported resolutions are \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mms\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mus\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mns\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m         )\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dtl\u001b[38;5;241m.\u001b[39mDatetimeLikeArrayMixin\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mself\u001b[39m, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot convert from timedelta64[ns] to timedelta64[h]. Supported resolutions are 's', 'ms', 'us', 'ns'"
     ]
    }
   ],
   "source": [
    "#create column to assign running time difference in hours\n",
    "#Zone 1\n",
    "df_zone1[\"timediff [h]\"] = 0\n",
    "df_zone1[\"timediff [h]\"] = (df_zone1[\"date\"] - df_zone1[\"date\"].shift(1)).astype(\"timedelta64[h]\")\n",
    "\n",
    "# replace first NaN with 0\n",
    "df_zone1[\"timediff [h]\"].fillna(0,inplace=True)\n",
    "df_zone1[\"timediff [h]\"] = df_zone1[\"timediff [h]\"].astype(\"int\")\n",
    "\n",
    "#rearrange columns\n",
    "df_zone1 = df_zone1[[\"date\", \"time [h]\", \"timediff [h]\", \"mass [kg]\", \"vel [m/s]\"]]\n",
    "\n",
    "display(df_zone1.head(5))\n",
    "\n",
    "#Zone 2\n",
    "df_zone2[\"timediff [h]\"] = 0\n",
    "df_zone2[\"timediff [h]\"] = (df_zone2[\"date\"] -\n",
    "                                       df_zone2[\"date\"].shift(1)).astype(\"timedelta64[h]\")\n",
    "\n",
    "# replace first NaN with 0\n",
    "df_zone2[\"timediff [h]\"].fillna(0,inplace=True)\n",
    "df_zone2[\"timediff [h]\"] = df_zone2[\"timediff [h]\"].astype(\"int\")\n",
    "\n",
    "#rearrange columns\n",
    "df_zone2 = df_zone2[[\"date\", \"time [h]\", \"timediff [h]\", \"mass [kg]\", \"vel [m/s]\"]]\n",
    "\n",
    "display(df_zone2.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kinetische Energie Berechnen <a name=\"datenerweiterung-2\"></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:12.468794Z",
     "start_time": "2023-06-12T10:37:12.435855Z"
    }
   },
   "outputs": [],
   "source": [
    "#zone 1\n",
    "df_zone1[\"KE [kJ]\"] = 0.5 * df_zone1[\"mass [kg]\"] * df_zone1[\"vel [m/s]\"]**2 / 1000\n",
    "\n",
    "#zone2\n",
    "df_zone2[\"KE [kJ]\"] = 0.5 * df_zone2[\"mass [kg]\"] * df_zone2[\"vel [m/s]\"]**2 / 1000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verbinden der beiden Datensätze <a name=\"datentransformation-1\"></a>\n",
    "\n",
    "Für spätere Analysen werden die Datensätze df_zone1 und df_zone2 zu zusammengeführt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:12.473983Z",
     "start_time": "2023-06-12T10:37:12.440985Z"
    }
   },
   "outputs": [],
   "source": [
    "#connect dfs\n",
    "df_zoneall = pd.concat([df_zone1, df_zone2])\n",
    "\n",
    "#sort data by Date\n",
    "df_zoneall.sort_values(by = \"date\", ascending = True, inplace = True)\n",
    "\n",
    "df_zoneall.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse der Daten <a name=\"dataanalysis\"></a>\n",
    "\n",
    "In diesem Abschnitt erfolgt eine Visualisierung und Analyse der Daten mittels Histogrammen und Streudiagrammen. Dadurch lassen sich potenzielle Ähnlichkeiten in den Datensätzen ermitteln."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:12.486631Z",
     "start_time": "2023-06-12T10:37:12.443421Z"
    }
   },
   "outputs": [],
   "source": [
    "#overview of dataframe df_zone1 and df_zone2\n",
    "df_zone1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:12.486840Z",
     "start_time": "2023-06-12T10:37:12.449440Z"
    }
   },
   "outputs": [],
   "source": [
    "df_zone2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplots <a name=\"dataanalysis-1\"></a>\n",
    "\n",
    "Im ersten Schritt der Datenanalyse erfolgt die Untersuchung der einzelnen Datensätze mittels Boxplots. Diese Methode ermöglicht eine detaillierte Visualisierung der Datenverteilung und fördert somit das Verständnis für ihre strukturellen Eigenschaften. Des Weiteren hilft sie dabei, potenzielle Ausreisser zu identifizieren, die eine bedeutende Auswirkung auf nachfolgende statistische Analysen und Modellierungen haben könnten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:12.625477Z",
     "start_time": "2023-06-12T10:37:12.456952Z"
    }
   },
   "outputs": [],
   "source": [
    "#boxplot of attributes \"mass\" and \"velocity\"\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\n",
    "\n",
    "#subplot 1\n",
    "ax1.boxplot(df_zone1[\"mass [kg]\"])\n",
    "ax1.set_xlabel(\"\", fontsize = 20)\n",
    "ax1.set_ylabel(\"[kg]\", fontsize = 20)\n",
    "ax1.set_title(\"Masse\", fontsize = 20)\n",
    "\n",
    "#subplot 1\n",
    "ax2.boxplot(df_zone1[\"vel [m/s]\"])\n",
    "ax2.set_ylabel(\"[m/s]\", fontsize = 20)\n",
    "ax2.set_title(\"Geschwindigkeit\", fontsize = 20)\n",
    "\n",
    "#overall title\n",
    "plt.suptitle(\"Erfasste Masse und Geschwindigkeit in Ablösezone 1\", fontsize = 35)\n",
    "\n",
    "#footnote\n",
    "x = -0.03\n",
    "y = -0.03\n",
    "ax1.text(x, y, \"Die Y-Achsen der Diagramme eins und zwei stehen in keiner direkten Beziehung zueinander\", fontsize=10,\n",
    "        horizontalalignment='left',verticalalignment='top', transform=ax1.transAxes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:12.826773Z",
     "start_time": "2023-06-12T10:37:12.561428Z"
    }
   },
   "outputs": [],
   "source": [
    "#boxplot of attributes \"mass\" and \"velocity\"\n",
    "fig1, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\n",
    "\n",
    "#subplot 1\n",
    "ax1.boxplot(df_zone2[\"mass [kg]\"])\n",
    "ax1.set_xlabel(\"\", fontsize = 20)\n",
    "ax1.set_ylabel(\"[kg]\", fontsize = 20)\n",
    "ax1.set_title(\"Masse\", fontsize = 20)\n",
    "\n",
    "\n",
    "#subplot 1\n",
    "ax2.boxplot(df_zone2[\"vel [m/s]\"])\n",
    "ax2.set_ylabel(\"[m/s]\", fontsize = 20)\n",
    "ax2.set_title(\"Geschwindigkeit\", fontsize = 20)\n",
    "\n",
    "\n",
    "#overall title\n",
    "plt.suptitle(\"Erfasste Masse und Geschwindigkeit in Ablösezone 2\", fontsize = 35)\n",
    "\n",
    "#footnote\n",
    "x = -0.03\n",
    "y = -0.03\n",
    "ax1.text(x, y, \"Die Y-Achsen der Diagramme eins und zwei stehen in keiner direkten Beziehung zueinander\", fontsize=10,\n",
    "        horizontalalignment='left',verticalalignment='top', transform=ax1.transAxes)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogramme <a name=\"dataanalysis-2\"></a>\n",
    "\n",
    "Um die Verteilung und Ausprägung der Daten weiter zu analysieren, werden Histogramme verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:12.979456Z",
     "start_time": "2023-06-12T10:37:12.683564Z"
    }
   },
   "outputs": [],
   "source": [
    "#Barplot of attributes \"time\", \"mass\" and \"velocity\"\n",
    "fig2, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (20, 10))\n",
    "\n",
    "#subplot 1\n",
    "ax1.hist(df_zone1[\"date\"])\n",
    "ax1.set_xlabel(\"\", fontsize = 15)\n",
    "ax1.set_ylabel(\"count\", fontsize = 15)\n",
    "ax1.set_xlabel(\"Monat\", fontsize = 15)\n",
    "ax1.set_title(\"Datum der Ablösungen\", fontsize = 15)\n",
    "ax1.xaxis.set_major_locator(mdates.MonthLocator(interval = 1))\n",
    "ax1.xaxis.set_major_formatter(mdates.DateFormatter(\"%b\"))\n",
    "\n",
    "\n",
    "#subplot 2\n",
    "ax2.hist(df_zone1[\"vel [m/s]\"])\n",
    "ax2.set_ylabel(\"count\", fontsize = 15)\n",
    "ax2.set_xlabel(\"Geschwindigkeit [m/s]\", fontsize = 15)\n",
    "ax2.set_title(\"Geschwindigkeit der Ablösungen\", fontsize = 15)\n",
    "\n",
    "#subplot 3\n",
    "ax3.hist(df_zone1[\"mass [kg]\"])\n",
    "ax3.set_ylabel(\"count\", fontsize = 15)\n",
    "ax3.set_xlabel(\"Masse [kg]\", fontsize = 15)\n",
    "ax3.set_title(\"Masse der Ablösungen\", fontsize = 15)\n",
    "\n",
    "#overall title\n",
    "plt.suptitle(\"Zeit, Geschwindigkeit und Masse in Ablösezone 1\", fontsize = 35)\n",
    "\n",
    "#footnote\n",
    "x = -0.03\n",
    "y = -0.1\n",
    "ax1.text(x, y, \"Die Y-Achsen der Diagramme stehen in keiner direkten Beziehung zueinander\", fontsize=10,\n",
    "        horizontalalignment='left',verticalalignment='top', transform=ax1.transAxes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:13.138207Z",
     "start_time": "2023-06-12T10:37:12.879648Z"
    }
   },
   "outputs": [],
   "source": [
    "#Barplot of attributes \"time\", \"mass\" and \"velocity\"\n",
    "fig3, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (20, 10))\n",
    "\n",
    "#subplot 1\n",
    "ax1.hist(df_zone2[\"date\"])\n",
    "ax1.set_xlabel(\"\", fontsize = 15)\n",
    "ax1.set_ylabel(\"count\", fontsize = 15)\n",
    "ax1.set_xlabel(\"Monat\", fontsize = 15)\n",
    "ax1.set_title(\"Datum der Ablösungen\", fontsize = 15)\n",
    "ax1.xaxis.set_major_locator(mdates.MonthLocator(interval = 1))\n",
    "ax1.xaxis.set_major_formatter(mdates.DateFormatter(\"%b\"))\n",
    "\n",
    "\n",
    "#subplot 2\n",
    "ax2.hist(df_zone2[\"vel [m/s]\"])\n",
    "ax2.set_ylabel(\"count\", fontsize = 15)\n",
    "ax2.set_xlabel(\"Geschwindigkeit [m/s]\", fontsize = 15)\n",
    "ax2.set_title(\"Geschwindigkeit der Ablösungen\", fontsize = 15)\n",
    "\n",
    "#subplot 3\n",
    "ax3.hist(df_zone2[\"mass [kg]\"])\n",
    "ax3.set_ylabel(\"count\", fontsize = 15)\n",
    "ax3.set_xlabel(\"Masse [kg]\", fontsize = 15)\n",
    "ax3.set_title(\"Masse der Ablösungen\", fontsize = 15)\n",
    "\n",
    "#overall title\n",
    "plt.suptitle(\"Zeit, Geschwindigkeit und Masse in Ablösezone 2\", fontsize = 35)\n",
    "\n",
    "#footnote\n",
    "x = -0.03\n",
    "y = -0.1\n",
    "ax1.text(x, y, \"Die Y-Achsen der Diagramme stehen in keiner direkten Beziehung zueinander\", fontsize=10,\n",
    "        horizontalalignment='left',verticalalignment='top', transform=ax1.transAxes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streudiagramme <a name=\"dataanalysis-3\"></a>\n",
    "\n",
    "Zur direkten Gegenüberstellung und Analyse der betreffenden Datensätze wurden Streudiagramme erstellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T11:10:06.992462Z",
     "start_time": "2023-06-12T11:10:06.789163Z"
    }
   },
   "outputs": [],
   "source": [
    "#compare mass of the fallen rocks\n",
    "fig5, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\n",
    "\n",
    "#subplot 1\n",
    "ax1.scatter(df_zone1[\"date\"], df_zone1[\"mass [kg]\"], s = 70)\n",
    "ax1.set_xlabel(\"Datum\", fontsize = 20)\n",
    "ax1.set_ylabel(\"Masse [kg]\", fontsize = 20)\n",
    "ax1.set_title(\"Ablösezone 1\", fontsize = 20)\n",
    "ax1.set_ylim(bottom=0, top=3200)\n",
    "\n",
    "#subplot 1\n",
    "ax2.scatter(df_zone2[\"date\"], df_zone2[\"mass [kg]\"], s = 70)\n",
    "ax2.set_xlabel(\"Datum\", fontsize = 20)\n",
    "ax2.set_ylabel(\"Masse [kg]\", fontsize = 20)\n",
    "ax2.set_title(\"Ablösezone 2\", fontsize = 20)\n",
    "ax2.set_ylim(bottom=0, top=3200)\n",
    "\n",
    "#overall title\n",
    "plt.suptitle(\"Vergleich der Masse von Ablösezone 1 und 2\", fontsize = 35)\n",
    "\n",
    "#add meanline\n",
    "zone1_mean = df_zone1[\"mass [kg]\"].mean()\n",
    "ax1.axhline(zone1_mean, color='r', linestyle='--')\n",
    "\n",
    "zone2_mean = df_zone2[\"mass [kg]\"].mean()\n",
    "ax2.axhline(zone2_mean, color='r', linestyle='--')\n",
    "\n",
    "\n",
    "#change angle of labels\n",
    "for ax in fig.axes:\n",
    "    ax.tick_params(labelrotation = 45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine Gegenüberstellung der beiden Ablösezonen zeigt, dass Steinschläge in Zone 1 häufiger vorkommen als in Zone 2. Weiter wird ersichtlich, dass sich im Zone 1 Steine mit grösserer Masse ablösen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T11:10:09.785766Z",
     "start_time": "2023-06-12T11:10:09.577844Z"
    }
   },
   "outputs": [],
   "source": [
    "#compare velocity of the fallen rocks\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\n",
    "\n",
    "#subplot 1\n",
    "ax1.scatter(df_zone1[\"date\"], df_zone1[\"vel [m/s]\"], s = 70)\n",
    "ax1.set_xlabel(\"Datum\", fontsize = 20)\n",
    "ax1.set_ylabel(\"Geschwindigkeit [m/s]\", fontsize = 20)\n",
    "ax1.set_title(\"Ablösezone 1\", fontsize = 20)\n",
    "ax1.set_ylim(bottom=0, top=60)\n",
    "\n",
    "#subplot 1\n",
    "ax2.scatter(df_zone2[\"date\"], df_zone2[\"vel [m/s]\"], s = 70)\n",
    "ax2.set_xlabel(\"Datum\", fontsize = 20)\n",
    "ax2.set_ylabel(\"Geschwindigkeit [m/s]\", fontsize = 20)\n",
    "ax2.set_title(\"Ablösezone 2\", fontsize = 20)\n",
    "ax2.set_ylim(bottom=0, top=60)\n",
    "\n",
    "#overall title\n",
    "plt.suptitle(\"Vergleich der Geschwindigkeit von Ablösezone 1 und 2\", fontsize = 35)\n",
    "\n",
    "#add meanline\n",
    "zone1_mean = df_zone1[\"vel [m/s]\"].mean()\n",
    "ax1.axhline(zone1_mean, color='r', linestyle='--')\n",
    "\n",
    "zone2_mean = df_zone2[\"vel [m/s]\"].mean()\n",
    "ax2.axhline(zone2_mean, color='r', linestyle='--')\n",
    "\n",
    "#change angle of labels\n",
    "for ax in fig.axes:\n",
    "    ax.tick_params(labelrotation = 45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steine welche sich aus Zone 1 ablösen, weisen eine geringere Geschwindigkeit auf, als jene die sich aus Zone 2 ablösen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zeitliche Verteilung der Steinschläge <a name=\"dataanalysis-4\"></a>\n",
    "\n",
    "Um einen Überblick über die zeitliche Verteilung von Steinschlägen zu erlangen, werden alle Ereignisse nach Stunden des Tages gruppiert.\n",
    "Dies ermöglicht eine konkrete statistische Analyse der zeitabhängigen Häufigkeit von Steinschlägen. Basierend auf diesen Daten kann dann untersucht werden, ob es bestimmte Zeitfenster gibt, in denen die Wahrscheinlichkeit für Steinschläge signifikant erhöht ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:13.380249Z",
     "start_time": "2023-06-12T10:37:13.074404Z"
    }
   },
   "outputs": [],
   "source": [
    "#sort df by time\n",
    "df_zone1.sort_values(by = \"time [h]\", inplace = True)\n",
    "df_zone2.sort_values(by = \"time [h]\", inplace = True)\n",
    "df_zoneall.sort_values(by = \"time [h]\", inplace = True)\n",
    "\n",
    "#create plot\n",
    "fig4, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (40, 10))\n",
    "\n",
    "#subplot 1\n",
    "ax1.hist(df_zone1[\"time [h]\"], bins=24)\n",
    "ax1.set_ylabel(\"count\", fontsize = 15)\n",
    "ax1.set_xlabel(\"Uhrzeit [h]\", fontsize = 15)\n",
    "ax1.set_title(\"Ablösezone 1\", fontsize = 15)\n",
    "ax1.set_ylim(bottom=0, top=10)\n",
    "\n",
    "#subplot 2\n",
    "ax2.hist(df_zone2[\"time [h]\"], bins=24)\n",
    "ax2.set_ylabel(\"count\", fontsize = 15)\n",
    "ax2.set_xlabel(\"Uhrzeit [h]\", fontsize = 15)\n",
    "ax2.set_title(\"Ablösezone 2\", fontsize = 15)\n",
    "ax2.set_ylim(bottom=0, top=10)\n",
    "\n",
    "#subplot 3\n",
    "ax3.hist(df_zoneall[\"time [h]\"], bins=24)\n",
    "ax3.set_ylabel(\"count\", fontsize = 15)\n",
    "ax3.set_xlabel(\"Uhrzeit [h]\", fontsize = 15)\n",
    "ax3.set_title(\"Beide Zonen\", fontsize = 15)\n",
    "ax3.set_ylim(bottom=0, top=10)\n",
    "\n",
    "#overall title\n",
    "plt.suptitle(\"Zeitpunkt der Ablösungen\", fontsize = 35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Bei der Kategorisierung der Ereignisse in Relation zur zugehörigen Uhrzeit ist eine signifikante Konzentration von Steinschlagvorfällen um die Mittagszeit zu erkennen, gefolgt von einer nachmittäglichen Abnahme. Der Grossteil der Steine fällt gegen 12 Uhr.\n",
    "\n",
    "Aufgrund der Tatsache, dass sich sowohl die Vorfälle als auch die Verkehrsdichte im Laufe des Tages wandeln, erscheint es logisch, den Verkehr in unsere Berechnungen miteinzubeziehen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stündliche Verkehrsdichte <a name=\"dataanalysis-4-1\"></a>\n",
    "\n",
    "Da die Verkehrsdichte in der Region Schiers nicht stündlich erfasst wird, ist eine Berufung auf die Durchschnittsdaten der Schweiz, die vom Bundesamt für Statistik (BFS) erhoben wurden, nötig. Die jüngsten verfügbaren Daten entstammen dem Bericht \"Verkehrsverhalten der Bevölkerung\" aus dem Jahr 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:13.384775Z",
     "start_time": "2023-06-12T10:37:13.380357Z"
    }
   },
   "outputs": [],
   "source": [
    "# import csv\n",
    "\n",
    "avg_traffic = pd.read_csv(\"/Users/christianheeb/Documents/PyCharm/cwm1_challenge/00_data/ch_traffic_density.csv\", sep = \";\")\n",
    "\n",
    "avg_traffic.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:13.643480Z",
     "start_time": "2023-06-12T10:37:13.394969Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.step(avg_traffic[\"h\"],avg_traffic[\"%\"])\n",
    "plt.title(\"Stündliche Verteilung des Verkehrs in der Schweiz\")\n",
    "plt.xlabel(\"Uhrzeit [h]\")\n",
    "plt.ylabel(\"Anteil [%]\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Darstellung des mittleren Verkehrsaufkommens zeigt, dass sich der Verkehr morgens aufbaut und seinen Höhepunkt am Nachmittag erreicht."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimale Verteilungsfunktion finden <a name=\"datadistribution\"></a>\n",
    "\n",
    "Um die optimale Wahrscheinlichkeitsverteilung für die gegebenen Daten zu ermitteln, erzeugen wir kumulative Verteilungsfunktionen (CDFs) basierend auf einer Reihe verschiedener theoretischer Verteilungen, einschliesslich der Normalverteilung und der Exponentialverteilung. Die Auswahl der korrekten Verteilungsannahme ist von entscheidender Bedeutung, da diese stark in die Simulationen einfliesst und folglich einen erheblichen Einfluss auf das endgültige Ergebnis hat.\n",
    "Dies führen wir mithilfe des \"Fitter\" Pakets durch. Das Fitter-Paket verwendet die Scipy-Bibliothek, welche 80 Verteilungsfunktionen unterstützt. Der Fitter scannt alle diese Verteilungen, ruft die Anpassungsfunktion auf, ignoriert diejenigen die fehlschlagen oder ewig laufen, und gibt schliesslich eine Zusammenfassung der besten Verteilungen im Sinne der Summe der quadratischen Fehler.\n",
    "Die Fitter-Bibliothek verfügt auch über eine Funktion get_common_distribution(), welche 10 gängigsten Verteilungen enthält. Um die Effizienz zu erhöhen und den Zeitaufwand zu minimieren, verwenden wir diese Funktion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beurteilung Ablösezone 1 <a name=\"dataexamination-1\"></a>\n",
    "\n",
    "### Geschwindigkeit <a name=\"dataexamination-1-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:14.161514Z",
     "start_time": "2023-06-12T10:37:13.858906Z"
    }
   },
   "outputs": [],
   "source": [
    "#convert data to NumPy array\n",
    "df1_vel = df_zone2[\"timediff [h]\"].values\n",
    "\n",
    "#fit common distributions to find best\n",
    "f = Fitter(df1_vel, distributions= get_common_distributions())\n",
    "f.fit()\n",
    "\n",
    "#shows the different distributions and fit statistics\n",
    "f.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Zusammenhang mit der Geschwindigkeit erweist sich der obere Bereich der Werte als von grösserer Bedeutung. Dies ist darauf zurückzuführen, dass Steine mit höherer Geschwindigkeit eine grössere Aufprallenergie aufweisen, die potenziell dazu beitragen kann, das Netz zu durchbrechen. Unter Berücksichtigung dieser Faktoren wird die Cauchy-Verteilung als die geeignetste Option ausgewählt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masse <a name=\"dataexamination-1-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:14.568682Z",
     "start_time": "2023-06-12T10:37:14.150973Z"
    }
   },
   "outputs": [],
   "source": [
    "#convert data to NumPy array\n",
    "df1_mas = df_zone1[\"mass [kg]\"].values\n",
    "\n",
    "#fit common distributions to find best\n",
    "f = Fitter(df1_mas, distributions= get_common_distributions())\n",
    "f.fit()\n",
    "\n",
    "#shows the different distributions and fit statistics\n",
    "f.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie auch bei der Geschwindigkeit, sind hier die höheren Werte von Wichtigkeit, da diese auch ein erhöhtes Potenzial zur Durchbrechung des Sicherheitsnetzes aufweisen. Deshalb eignet sich für diese Daten die Gamma-Verteilung am besten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zeitdifferenz <a name=\"dataexamination-1-3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:14.951686Z",
     "start_time": "2023-06-12T10:37:14.526667Z"
    }
   },
   "outputs": [],
   "source": [
    "#convert data to NumPy array\n",
    "df1_date = df_zone1[\"timediff [h]\"].values\n",
    "\n",
    "#fit common distributions to find best\n",
    "f = Fitter(df1_date, distributions = get_common_distributions())\n",
    "f.fit()\n",
    "\n",
    "#shows the different distributions and fit statistics\n",
    "f.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Unterschied zu Massen- und Geschwindigkeitsparametern ist im Kontext der Zeitabstände der untere Bereich von besonderem Interesse. Dies ist auf die Tatsache zurückzuführen, dass bei geringeren Zeitabständen zwischen den Steinschlägen mehr Steine auf das Netz treffen können, bevor eine Leerung stattfindet. Deshalb wird hier die Entscheidung für die Gamma-Verteilung getroffen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beurteilung der Ablösezone 2 <a name=\"dataexamination-2\"></a>\n",
    "\n",
    "### Geschwindigkeit <a name=\"dataexamination-2-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:15.283490Z",
     "start_time": "2023-06-12T10:37:14.937305Z"
    }
   },
   "outputs": [],
   "source": [
    "#convert data to NumPy array\n",
    "df2_vel = df_zone2[\"vel [m/s]\"].values\n",
    "\n",
    "#fit common distributions to find best\n",
    "f = Fitter(df2_vel, distributions= get_common_distributions())\n",
    "f.fit()\n",
    "\n",
    "#shows the different distributions and fit statistics\n",
    "f.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da die Powerlaw-Verteilung im Bereich der hohen Geschwindigkeiten (> 40 m/s) eine gute Anpassung aufweist, wurde diese ausgewählt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masse <a name=\"dataexamination-2-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:15.609821Z",
     "start_time": "2023-06-12T10:37:15.270464Z"
    }
   },
   "outputs": [],
   "source": [
    "#convert data to NumPy array\n",
    "df2_mas = df_zone2[\"mass [kg]\"].values\n",
    "\n",
    "#fit common distributions to find best\n",
    "f = Fitter(df2_mas, distributions= get_common_distributions())\n",
    "f.fit()\n",
    "\n",
    "#shows the different distributions and fit statistics\n",
    "f.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aus den gleichen Gründen wie bei Ablösezone 1, wurde hier die Gamma-Verteilung ausgewählt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zeitdifferenz <a name=\"dataexamination-2-3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:15.911252Z",
     "start_time": "2023-06-12T10:37:15.599894Z"
    }
   },
   "outputs": [],
   "source": [
    "#convert data to NumPy array\n",
    "df2_date = df_zone2[\"timediff [h]\"].values\n",
    "\n",
    "#fit common distributions to find best\n",
    "f = Fitter(df2_date, distributions = get_common_distributions())\n",
    "f.fit()\n",
    "\n",
    "#shows the different distributions and fit statistics\n",
    "f.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Logonorn-Verteilung weist die höchste übereinstimmung auf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Übersicht der ausgewählten Verteilungen in Zone 1 und 2 <a name=\"dataexamination-1-and-2\"></a>\n",
    "\n",
    "| Attribut              | Verteilung           |\n",
    "|:----------------------|:---------------------|\n",
    "| df_zone1 vel [m/s]    | Cauchy               |\n",
    "| df_zone1 mass [kg]    | Gamma                |\n",
    "| df_zone1 timediff [h] | Gamma                |\n",
    "| df_zone2 vel [m/s]    | Powerlaw             |\n",
    "| df_zone2 mass [kg]    | Gamma                |\n",
    "| df_zone2 timediff [h] | Lognorn |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation der Daten <a name=\"datasimulation\"></a>\n",
    "\n",
    "Für die Simulation kommt die Monte-Carlo-Methodik zum Einsatz. Hierbei erfolgt die Simulation numerischer Werte auf der Grundlage vorab definierter Verteilungen durch Einsatz der Funktionen von scipy.stats.\n",
    "\n",
    "Die Zuverlässigkeit einer Monte-Carlo-Simulation ist stark von der Anzahl der Durchläufe abhängig. Ideal für die Analyse wäre eine möglichst hohe Anzahl von Durchläufen. Allerdings steigt mit zunehmender Anzahl der Durchläufe auch der Rechenaufwand. Unter Berücksichtigung dieser Aspekte wurde ein Kompromiss gefunden und die Durchlaufanzahl auf 10 Millionen festgelegt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:15.911407Z",
     "start_time": "2023-06-12T10:37:15.907135Z"
    }
   },
   "outputs": [],
   "source": [
    "#numer of Simulations\n",
    "number_of_simulations = 10_000_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation der Zone 1 <a name=\"datasimulation-1\"></a>\n",
    "\n",
    "Nach der Simulation werden die Daten in den Datensatz df_zone1_sim und df_zone2_sim eingefügt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:17.292496Z",
     "start_time": "2023-06-12T10:37:15.907366Z"
    }
   },
   "outputs": [],
   "source": [
    "#create df\n",
    "df_zone1_sim = pd.DataFrame()\n",
    "\n",
    "\n",
    "#simulate Velocity\n",
    "param = stats.cauchy.fit(df_zone1[\"vel [m/s]\"])\n",
    "zone1_vel = stats.cauchy.rvs(*param, size = number_of_simulations)\n",
    "#insert values\n",
    "df_zone1_sim.insert(0, \"vel [m/s]\", zone1_vel)\n",
    "\n",
    "#simulate Mass\n",
    "param = stats.gamma.fit(df_zone1[\"mass [kg]\"])\n",
    "zone1_mass = stats.gamma.rvs(*param, size = number_of_simulations)\n",
    "#insert values\n",
    "df_zone1_sim.insert(1, \"mass [kg]\", zone1_mass)\n",
    "\n",
    "#simulate time difference\n",
    "param = stats.gamma.fit(df_zone1[\"timediff [h]\"])\n",
    "zone1_timediff = stats.gamma.rvs(*param, size = number_of_simulations)\n",
    "#insert values\n",
    "df_zone1_sim.insert(2, \"timediff [h]\", zone1_timediff)\n",
    "#round timediff values\n",
    "df_zone1_sim[\"timediff [h]\"] = zone1_timediff.round(2)\n",
    "df_zone1_sim[\"timediff [h]\"][0] = 0\n",
    "\n",
    "#calculate and insert energy in kj for generated values\n",
    "df_zone1_sim.insert(3, \"KE [kJ]\", \"\")\n",
    "df_zone1_sim[\"KE [kJ]\"] = 0.5 * df_zone1_sim[\"mass [kg]\"] * df_zone1_sim[\"vel [m/s]\"] ** 2 / 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:17.297007Z",
     "start_time": "2023-06-12T10:37:17.294469Z"
    }
   },
   "outputs": [],
   "source": [
    "df_zone1_sim.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation der Zone 2 <a name=\"datasimulation-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:18.450355Z",
     "start_time": "2023-06-12T10:37:17.306991Z"
    }
   },
   "outputs": [],
   "source": [
    "#create df\n",
    "df_zone2_sim = pd.DataFrame()\n",
    "\n",
    "#simulate Velocity\n",
    "param = stats.powerlaw.fit(df_zone2[\"vel [m/s]\"])\n",
    "zone2_vel = stats.powerlaw.rvs(*param, size = number_of_simulations)\n",
    "#insert values\n",
    "df_zone2_sim.insert(0, \"vel [m/s]\", zone2_vel)\n",
    "\n",
    "#simulate Mass\n",
    "param = stats.gamma.fit(df_zone2[\"mass [kg]\"])\n",
    "zone2_mass = stats.gamma.rvs(*param, size = number_of_simulations)\n",
    "#insert values\n",
    "df_zone2_sim.insert(1, \"mass [kg]\", zone2_mass)\n",
    "\n",
    "#simulate time difference\n",
    "param = stats.lognorm.fit(df_zone2[\"timediff [h]\"])\n",
    "zone2_timediff = stats.lognorm.rvs(*param, size = number_of_simulations)\n",
    "#insert values\n",
    "df_zone2_sim.insert(2, \"timediff [h]\", zone2_timediff)\n",
    "#round timediff values\n",
    "df_zone2_sim[\"timediff [h]\"] = zone2_timediff.round(2)\n",
    "df_zone2_sim[\"timediff [h]\"][0] = 0\n",
    "\n",
    "#calculate and insert energy in kj for generated values\n",
    "df_zone2_sim.insert(3, \"KE [kJ]\", \"\")\n",
    "df_zone2_sim[\"KE [kJ]\"] = 0.5 * df_zone2_sim[\"mass [kg]\"] * df_zone2_sim[\"vel [m/s]\"] ** 2 / 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:18.455193Z",
     "start_time": "2023-06-12T10:37:18.451946Z"
    }
   },
   "outputs": [],
   "source": [
    "df_zone2_sim.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für weitere Berechnungen wird den kumulierten Zeitabstand berechnet und zu den Datensätzen df_zone1_sim und df_zone2_sim hinzugefügt. Anschliessend werden die Datensätze zusammengefügt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:19.295104Z",
     "start_time": "2023-06-12T10:37:18.455469Z"
    }
   },
   "outputs": [],
   "source": [
    "#calculate and insert cumulative timediff\n",
    "df_zone1_sim.insert(4, \"cum timediff [h]\", \"\")\n",
    "df_zone1_sim[\"cum timediff [h]\"] = df_zone1_sim[\"timediff [h]\"].cumsum()\n",
    "df_zone1_sim.head(5)\n",
    "\n",
    "df_zone2_sim.insert(4, \"cum timediff [h]\", \"\")\n",
    "df_zone2_sim[\"cum timediff [h]\"] = df_zone2_sim[\"timediff [h]\"].cumsum()\n",
    "df_zone1_sim.head(5)\n",
    "\n",
    "df_zone1_sim = df_zone1_sim.drop(df_zone1_sim[df_zone1_sim[\"cum timediff [h]\"] > max(df_zone2_sim[\"cum timediff [h]\"])].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:21.806385Z",
     "start_time": "2023-06-12T10:37:19.295292Z"
    }
   },
   "outputs": [],
   "source": [
    "df_simulations = pd.concat([df_zone1_sim, df_zone2_sim], ignore_index = True)\n",
    "\n",
    "#sort df_simulations by time\n",
    "df_simulations.sort_values(by = \"cum timediff [h]\", inplace = True)\n",
    "\n",
    "#renew index of combined dfs\n",
    "df_simulations = df_simulations.reset_index()\n",
    "df_simulations = df_simulations.drop(['index'], axis=1)\n",
    "\n",
    "#rearrange columns\n",
    "df_simulations = df_simulations[[\"mass [kg]\", \"vel [m/s]\", \"KE [kJ]\", \"timediff [h]\", \"cum timediff [h]\"]]\n",
    "\n",
    "\n",
    "df_simulations.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:24.263617Z",
     "start_time": "2023-06-12T10:37:21.807494Z"
    }
   },
   "outputs": [],
   "source": [
    "df_simulations.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:25.024636Z",
     "start_time": "2023-06-12T10:37:25.021182Z"
    }
   },
   "outputs": [],
   "source": [
    "#calculate simulated years\n",
    "simulated_years = max(df_simulations[\"cum timediff [h]\"]) / 8760 #hours in a Year\n",
    "\n",
    "simulated_years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bedingung für das Zerreissen des Sicherheitsnetzes <a name=\"requirements\"></a>\n",
    "\n",
    "Ausgangslage:\n",
    "Es wurde geschätzt, dass die Sicherheitsnetze bis zu einer Aufprallenergie von 1000 kJ sicher sind. Falls bereits ein Stein mit über 2000 kg in den Sicherheitsnetzen liegt, beträgt die Aufprallenergie, die von den Sicherheitsnetzen aufgenommen werden kann, nur noch 500 kJ. Steine in den Sicherheitsnetzen werden vom Unterhaltsteam entfernt (die Reaktionszeit beträgt 24 Stunden)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:25.026981Z",
     "start_time": "2023-06-12T10:37:25.025107Z"
    }
   },
   "outputs": [],
   "source": [
    "#Function to determine when the net breaks\n",
    "def durchbruch(mass, energy, cum_mass):\n",
    "    #Safetynet breaks\n",
    "    if energy >= 1000:\n",
    "        return True\n",
    "\n",
    "    #Breakthrough when stones with total weight of 200kg are already in the net and the impact energy is more than 500kj\n",
    "    elif energy >= 500 and cum_mass >= 2000:\n",
    "        return True\n",
    "\n",
    "    #no Breakthrough\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:36.682428Z",
     "start_time": "2023-06-12T10:37:25.102689Z"
    }
   },
   "outputs": [],
   "source": [
    "cum_timediff = 0\n",
    "cum_mass = 0\n",
    "breakthroughs = 0\n",
    "\n",
    "for row in df_simulations.itertuples():\n",
    "    mass = row[1]\n",
    "    vel = row[2]\n",
    "    energy = row[3]\n",
    "    timediff = row[5]\n",
    "\n",
    "    #count the number of breakthroughs if the net breaks\n",
    "    if durchbruch(mass, energy, cum_mass):\n",
    "        breakthroughs += 1\n",
    "\n",
    "    #timediff > 24h -> Safety net gets emptied and counter is set back\n",
    "    if timediff >= 24:\n",
    "        cum_timediff = 0\n",
    "        cum_mass = 0\n",
    "\n",
    "    #timediff and cum_timediff >=24h -> Safety net gets emptied\n",
    "    if timediff + cum_timediff >= 24:\n",
    "        cum_timediff = 0\n",
    "        cum_mass = 0\n",
    "\n",
    "    #Sumup time intervals and mass\n",
    "    else:\n",
    "        cum_timediff += timediff\n",
    "        cum_mass += mass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:36.685479Z",
     "start_time": "2023-06-12T10:37:36.683368Z"
    }
   },
   "outputs": [],
   "source": [
    "#print breakthroughs per year\n",
    "breakthroughs_per_year = breakthroughs / simulated_years\n",
    "\n",
    "print(\"Total Simulierte Jahre: {}\".format(f\"{simulated_years:.2f}\"))\n",
    "print(\"Total Durchbrüche: {}\".format(breakthroughs))\n",
    "print(\"Total Durchbrüche / Jahr: {}\".format(f\"{breakthroughs_per_year:.2f}\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto wird von Stein getroffen <a name=\"usecase-1\"></a>\n",
    "\n",
    "Ausgangslage:\n",
    "Das tägliche Verkehrsaufkommen beträgt 1200 Autos (50/h). Stau kommt auf der Strecke nicht vor. Die Tempolimite beträgt 60 km/h.\n",
    "\n",
    "Bezüglich der durchschnittlichen Anzahl Personen in einem Fahrzeug müssen wir uns auf Schweizer den Schweizer Durchschnitt berufen, welcher durch das BFS erhoben wurden. Diese ist gemäss dem Bericht \"Verkehrsverhalten der Bevölkerung\" aus dem Jahr 2015, 1.56 Personen pro Fahrzeug.\n",
    "\n",
    "Gemäss einer Analyse des ADAC waren die Autos im Jahr 2020 im Durchschnitt 4,60 Meter lang. Da sich aber der Fahrer und Beifahrer nur in einem kleinen Teil des Autos aufhalten, wird mit einer \"kritische\" länge eines Autos von 1,5 Meter gerechnet.\n",
    "\n",
    "\n",
    "Szenarien:\n",
    "\n",
    "Erreicht ein Stein die Strasse, können mehrere Szenarien auftreten:\n",
    "1. Stein liegt auf der Strasse und wird von den Verkehrsteilnehmern bemerkt\n",
    "2. Stein liegt auf der Strasse und ein Auto fährt in den Stein\n",
    "3. Stein trifft das Auto\n",
    "\n",
    "In Szenario 1 erfolgt kein Personenschaden. Dagegen könnte es in Szenario 2 zu möglichen Verletzungen oder Todesfällen kommen. Da dieses Szenario jedoch erhebliche Ungewissheiten birgt und somit nur ungenau berechnet werden kann, liegt der Fokus der Berechnung auf Szenario 3.\n",
    "\n",
    "Daraus berechnet sich die Gefahr für einen tödlichen Treffer wie folgt:\n",
    "\n",
    "Die Wahrscheinlichkeit, dass sich ein Fahrzeug in der Gefahrenzone befindet, multipliziert mit der Wahrscheinlichkeit, dass ein Stein das Sicherheitsnetz durchschlägt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:36.687957Z",
     "start_time": "2023-06-12T10:37:36.686155Z"
    }
   },
   "outputs": [],
   "source": [
    "#set Variables\n",
    "car_length = 1.5\n",
    "people_in_car = 1.56\n",
    "car_speed = 60\n",
    "distance_per_second = car_speed / 3.6\n",
    "number_of_cars_seconds = 1200 / 24 / 60 / 60\n",
    "\n",
    "#Probability that a car will be hit directly by a rock\n",
    "fatal_hit = car_length / distance_per_second * number_of_cars_seconds\n",
    "\n",
    "#Death probability per year\n",
    "fatal_hit_per_year = fatal_hit * people_in_car * breakthroughs_per_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fazit <a name=\"simulation-result\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T10:37:36.690678Z",
     "start_time": "2023-06-12T10:37:36.688997Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Die Todeswahrscheinlichkeit durch Steinschlag auf der Kantonstrasse von Schiers Beträgt: {}\".format(f\"{fatal_hit_per_year:.10f}\"))\n",
    "if fatal_hit_per_year >= 0.0001:\n",
    "    print(\"Somit muss die Strasse gesperrt werden.\")\n",
    "else:\n",
    "    print(\"Somit kann die Strasse weiterhin geöffnet bleiben\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quellengrundlage <a name=\"sources\"></a>\n",
    "\n",
    "Cramer, E., & Kamps, U. (2017). Grundlagen der Wahrscheinlichkeitsrechnung und Statistik: Eine Einführung für Studierende der Informatik, der Ingenieur- und Wirtschaftswissenschaften (4., korrigierte und erweiterte Auflage). Springer Spektrum. https://doi.org/10.1007/978-3-662-54161-6\n",
    "\n",
    "Fahrmeir, L., Heumann, C., Künstler, R., Pigeot, I., & Tutz, G. (2016). Statistik: Der Weg zur Datenanalyse (8., überarbeitete und ergänzte Auflage). Springer Spektrum. https://doi.org/10.1007/978-3-662-50372-0\n",
    "\n",
    "Ruiz-Carulla, R., Corominas, J., & Mavrouli, O. (2017). A fractal fragmentation model for rockfalls. Landslides, 14(3), 875–889. https://doi.org/10.1007/s10346-016-0773-8\n",
    "\n",
    "Raoniar, R. (2022, September 9). Finding the Best Distribution that Fits Your Data using Python’s Fitter Library. The Researchers’ Guide. https://medium.com/the-researchers-guide/finding-the-best-distribution-that-fits-your-data-using-pythons-fitter-library-319a5a0972e9\n",
    "\n",
    "Biedermann, F. (2017). Verkehrsverhalten der Bevölkerung 2015. Bundesamt für Statistik (BFS).\n",
    "\n",
    "Christ, J. (2020, Februar 15). Datenanalyse: Autos werden nicht erst seit dem SUV-Boom grösser. https://www.rnd.de/wirtschaft/datenanalyse-autos-werden-nicht-erst-seit-dem-suv-boom-grosser-6GTM66RRNJEC7EYHR3FQS7Y24Y.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
